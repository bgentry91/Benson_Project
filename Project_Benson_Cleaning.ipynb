{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T17:09:41.365516Z",
     "start_time": "2018-01-15T17:09:38.480024Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T17:09:47.599263Z",
     "start_time": "2018-01-15T17:09:41.368184Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# import data from MTA\n",
    "# set intial date, set weeks to pull data\n",
    "string_date = '170527'\n",
    "weeks = 4\n",
    "\n",
    "pull_date = datetime.strptime(string_date, '%y%m%d')\n",
    "df = pd.read_csv(\n",
    "    'http://web.mta.info/developers/data/nyct/turnstile/turnstile_' + string_date + '.txt')\n",
    "\n",
    "for i in range(weeks - 1):\n",
    "    pull_date = pull_date - timedelta(days=7)\n",
    "    string_date = datetime.strftime(pull_date, '%y%m%d')\n",
    "    df = df.append(pd.read_csv('http://web.mta.info/developers/data/nyct/turnstile/turnstile_' + string_date + '.txt'),\n",
    "                   ignore_index=True)\n",
    "\n",
    "df.rename(columns=lambda x: x.rstrip(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:11:42.336219Z",
     "start_time": "2018-01-15T16:10:29.268046Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# build timestamp fields\n",
    "# get rid of unnecessary fields\n",
    "df['timestamp'] = df.apply(lambda x: datetime.strptime(\n",
    "    x['DATE'] + ' ' + x['TIME'], '%m/%d/%Y %H:%M:%S'), axis=1)\n",
    "del df['LINENAME']\n",
    "del df['DIVISION']\n",
    "del df['DATE']\n",
    "del df['TIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:16:06.529315Z",
     "start_time": "2018-01-15T16:11:42.552865Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# This is for binning the data into four hour increments\n",
    "# Copy the original dataframe for ease of use\n",
    "df_timestamps = df.copy()\n",
    "\n",
    "# set bins size (hour increments)\n",
    "bin_size = 4\n",
    "\n",
    "# create bins (in hours) int(x)*x gets closest 4 hours\n",
    "df_timestamps['hours'] = df_timestamps.apply(lambda x:\n",
    "                                             int(((x['timestamp']).timestamp()\n",
    "                                                  / 3600) / bin_size) * bin_size,\n",
    "                                             axis=1)\n",
    "# return bins to datetime format\n",
    "df_timestamps['bin'] = df_timestamps.apply(lambda x: datetime.fromtimestamp(x['hours'] * 3600),\n",
    "                                           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:16:08.794022Z",
     "start_time": "2018-01-15T16:16:06.550440Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# group by the bins - take min of entries/exits\n",
    "# this should give us the first value for that time period, assuming it is increasing\n",
    "# sort the records & take the difference of the bins - we want this to be 4, but sometimes it's not!\n",
    "df_grouped_bin = df_timestamps.groupby(\n",
    "    ['C/A', 'UNIT', 'SCP', 'STATION', 'bin']).agg({'ENTRIES': 'min', 'EXITS': 'min'})\n",
    "df_grouped_bin.reset_index(inplace=True)\n",
    "df_grouped_bin.sort_values(\n",
    "    ['C/A', 'UNIT', 'SCP', 'STATION', 'bin'], inplace=True)\n",
    "df_grouped_bin['diff'] = df_grouped_bin.bin.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:16:08.810705Z",
     "start_time": "2018-01-15T16:16:08.798114Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# For the next couple cells,\n",
    "# create all of the different possible bins\n",
    "string_date = '170528'\n",
    "\n",
    "# create starting point\n",
    "first_datetime = datetime.strptime(\n",
    "    string_date + ' 00:00:00', '%y%m%d %H:%M:%S')\n",
    "\n",
    "# interate through all of the 4 hour possibilities (time bins)\n",
    "bin_dict = defaultdict(list)\n",
    "for i in range(0, 42 * weeks):\n",
    "    bin_dict['bin'].append(first_datetime - timedelta(hours=4 * i))\n",
    "\n",
    "# create bin dataframe\n",
    "bin_df = pd.DataFrame(bin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:16:09.403081Z",
     "start_time": "2018-01-15T16:16:08.815224Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# set df2 to all the possible combinations of the key\n",
    "df2 = df[['C/A', 'UNIT', 'SCP', 'STATION']].copy()\n",
    "df2.drop_duplicates(inplace=True)\n",
    "df2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:16:09.715048Z",
     "start_time": "2018-01-15T16:16:09.406827Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a df of all possible key/bin combinations\n",
    "all_df = df2.assign(foo=1).merge(bin_df.assign(foo=1)).drop('foo', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:16:11.911247Z",
     "start_time": "2018-01-15T16:16:09.718378Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# left join the dataframe with all combinations with data\n",
    "# if we're missing values for a bin, they will be null\n",
    "new_df = pd.merge(all_df, df_grouped_bin,\n",
    "                  how='left',\n",
    "                  left_on=['C/A', 'UNIT', 'SCP', 'STATION', 'bin'],\n",
    "                  right_on=['C/A', 'UNIT', 'SCP', 'STATION', 'bin'])\n",
    "\n",
    "\n",
    "del new_df['diff']\n",
    "new_df.sort_values(['C/A', 'UNIT', 'SCP', 'STATION', 'bin'], inplace=True)\n",
    "new_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:16:11.932648Z",
     "start_time": "2018-01-15T16:16:11.915209Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# function to get the median between two values\n",
    "def get_median(prev_val, next_val):\n",
    "    try:\n",
    "        return(prev_val + next_val) / 2\n",
    "    except:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:21:27.092253Z",
     "start_time": "2018-01-15T16:16:11.935246Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate the median & input if an entry is missing\n",
    "# this will not work if two consecutive entries are blank\n",
    "# helps a bit\n",
    "\n",
    "# get next and last entry & exit to calculate\n",
    "new_df['previous_ent'] = new_df['ENTRIES'].shift(1)\n",
    "new_df['next_ent'] = new_df['ENTRIES'].shift(-1)\n",
    "new_df['previous_exit'] = new_df['EXITS'].shift(1)\n",
    "new_df['next_exit'] = new_df['EXITS'].shift(-1)\n",
    "\n",
    "# actually calculate the medians\n",
    "new_df['calc_ent'] = new_df.apply(lambda x: get_median(x['previous_ent'], x['next_ent'])\n",
    "                                  if np.isnan(x['ENTRIES'])\n",
    "                                  else x['ENTRIES'],\n",
    "                                  axis=1)\n",
    "new_df['calc_exit'] = new_df.apply(lambda x: get_median(x['previous_exit'], x['next_exit'])\n",
    "                                   if np.isnan(x['EXITS'])\n",
    "                                   else x['EXITS'],\n",
    "                                   axis=1)\n",
    "# delete unnecessary rows used for calculation\n",
    "del new_df['ENTRIES']\n",
    "del new_df['EXITS']\n",
    "del new_df['previous_ent']\n",
    "del new_df['next_ent']\n",
    "del new_df['previous_exit']\n",
    "del new_df['next_exit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:31:42.186622Z",
     "start_time": "2018-01-15T16:21:27.101034Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# get differences between each bin\n",
    "new_df['Entry_Count'] = new_df.calc_ent.diff(-1)\n",
    "new_df['Exit_Count'] = new_df.calc_exit.diff(-1)\n",
    "\n",
    "# deal with negative values - sometimes its decrementing, so this accounts for that\n",
    "new_df['Entry_Count'] = new_df.apply(lambda x: -x['Entry_Count']\n",
    "                                     if x['Entry_Count'] < 0\n",
    "                                     else x['Entry_Count'],\n",
    "                                     axis=1)\n",
    "\n",
    "new_df['Exit_Count'] = new_df.apply(lambda x: -x['Exit_Count']\n",
    "                                    if x['Exit_Count'] < 0\n",
    "                                    else x['Exit_Count'],\n",
    "                                    axis=1)\n",
    "\n",
    "# if a value is too big to make sense, just make it zero\n",
    "max_entry_count = 5000\n",
    "\n",
    "new_df['Entry_Count'] = new_df.apply(lambda x: 0\n",
    "                                     if x['Entry_Count'] > max_entry_count\n",
    "                                     else x['Entry_Count'],\n",
    "                                     axis=1)\n",
    "\n",
    "new_df['Exit_Count'] = new_df.apply(lambda x: 0\n",
    "                                    if x['Exit_Count'] > max_entry_count\n",
    "                                    else x['Exit_Count'],\n",
    "                                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:31:42.252438Z",
     "start_time": "2018-01-15T16:31:42.200837Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# if there are still N/A values, make them zero\n",
    "# there are not many, and they probably aren't worth recovering\n",
    "new_df['Entry_Count'].fillna(0, inplace=True)\n",
    "new_df['Exit_Count'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:31:53.287890Z",
     "start_time": "2018-01-15T16:31:42.257617Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# group by station and bin to determine the total traffic for each station/time period\n",
    "df_st_bin = new_df.groupby([\"STATION\", \"bin\"]).agg(\n",
    "    {'Entry_Count': 'sum', 'Exit_Count': 'sum'})\n",
    "df_st_bin.reset_index(inplace=True)\n",
    "\n",
    "# total entries and exits\n",
    "df_st_bin['Total_Traffic'] = df_st_bin.apply(\n",
    "    lambda x: x['Entry_Count'] + x['Exit_Count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:32:35.952893Z",
     "start_time": "2018-01-15T16:31:53.292257Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# function to make cleanly named bin size\n",
    "def convert_to_range(first, second):\n",
    "    try:\n",
    "        return(datetime.strftime(first, \"%H:%M\") + \" to \" + datetime.strftime(second, \"%H:%M\"))\n",
    "    except:\n",
    "        return(float('NaN'))\n",
    "\n",
    "\n",
    "# make a clean dataframe to be output to .CSV\n",
    "# this will be used in the visualization notebooks\n",
    "output_df = df_st_bin.copy()\n",
    "\n",
    "output_df['Day'] = output_df.apply(\n",
    "    lambda x: datetime.strftime(x['bin'], \"%A\"), axis=1)\n",
    "output_df['next_bin'] = output_df['bin'].shift(-1)\n",
    "output_df['Time_Range'] = output_df.apply(\n",
    "    lambda x: convert_to_range(x['bin'], x['next_bin']), axis=1)\n",
    "output_df['DT'] = output_df.apply(\n",
    "    lambda x: datetime.strftime(x['bin'], '%m/%d/%Y'), axis=1)\n",
    "\n",
    "# get rid of unnecessary columns\n",
    "del output_df['bin']\n",
    "del output_df['next_bin']\n",
    "del output_df['Entry_Count']\n",
    "del output_df['Exit_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T16:32:36.470148Z",
     "start_time": "2018-01-15T16:32:35.959976Z"
    },
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# output this to CSV for blog visualizations\n",
    "output_df.to_csv('data/station_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the output_DF based on mean for each time period\n",
    "# before, we had a record for every time period combination\n",
    "# this makes the data weekly\n",
    "output_df = output_df.groupby(['STATION', 'Day', 'Time_Range'])[\n",
    "    'Total_Traffic'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-15T17:10:01.784074Z",
     "start_time": "2018-01-15T17:09:59.935763Z"
    }
   },
   "outputs": [],
   "source": [
    "# output this to CSV for project visualizations\n",
    "df.to_csv('data/average_station_traffic.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
